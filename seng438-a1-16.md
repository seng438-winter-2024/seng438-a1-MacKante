# **SENG 438 - Software Testing, Reliability, and Quality**

## **Lab. Report \#1 â€“ Introduction to Testing and Defect Tracking**

| Group: 16                              |
|----------------------------------------|
| Student 1: Dominic Choi                |   
| Student 2: Nathan Ante                 |   
| Student 3: Karam Baroud                |   
| Student 4: Angelo  Jerome T. Reynante  |   


**Table of Contents**
[1 Introduction](#introduction)

[2 High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)

[3 Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-team-workeffort-was-divided)

[6 Lessons learned from teamwork on this lab](#lessons-learned-from-teamwork-on-this-lab)

[7 Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)

[8 Comments/feedback on the lab and lab document itself](#commentsfeedback-on-the-lab-and-lab-document-itself)

# Introduction

An introduction of your lab work, and what you knew about exploratory and manual functional testing before this lab

In this lab, our group is meant to perform three types of testing on a bank ATM simulation. First, we perform exploratory testing by creating a basic plan of what to do and then investigating the application. Second, we perform manual scripted testing by executing the instructions of the test cases found in Appendix C. Finally, we perform regression testing on a newer version of the system to see if bugs from the older version are still present or have been resolved, or if entirely new bugs have been created.

Our initial knowledge of exploratory and manual testing came from content covered in lectures. The lectures explained that exploratory testing involves testing software based on personal knowledge of what it is supposed to do. You are meant to jump in to the application and "explore" it to find bugs and issues. Manual scripted testing involves creating and designing test cases before attempting to test the system. After these test cases are made, the designer or someone else entirely should be able to follow along with the test cases and test the system.

# High-level description of the exploratory testing plan

Our exploratory test plan is to go through the system requirements found in Appendix B and check if each one functions properly. 
Tasks:
- Authentication:
    - Try using ATM before inserting card
    - Enter incorrect pins multiple times until card is permanently retained
- Transactions
    - After each transaction, check for accurate receipts
    - Make a withdrawal in multiples of 20 and try to make withdrawal not in multiples of 20
    - Try depositing with both cash and checks
    - Attempt money transfer between different accounts
    - Make balance inquiries on each linked account 
    - Abort a transaction in progress(maybe at different stages of the transaction)
    - Select deposit and wait for the timeout
- Operator
    - Turn switch to "on" and verify cash on hand
    - Try turning machine "off"
    - Try turning machine "off" while servicing customer
    - Use machine in "off" mode
- Logs
    - Check for PINs in logs
    - Verify two messages for deposits
    - Check start up and shut down messages
    - Verify message


# Comparison of exploratory and manual functional testing

Exploratory Testing:
- Approach:
    - Understand system requirements outlined in Appendix B
    - Create and follow an exploratory test plan
    - Make Changes to the test plan when needed
- Execution:
    - Carry out tests in test plan in groups of 2
    - Report defects as they are found in testing
    - Group review of all defects
- Benefits:
    - You are able to go straight into testing without needing to wait for a test suite to be created
    - More realistic scenarios
    - More comprehensive coverage as testing is unscripted, you may explore more outside the coverage of the test cases
- Tradeoffs:
    - Heavily reliant on skills and efficiency of the tester
    - Difficult to test larger and more complex systems
    - Hard to repeat testing
    - Hard to track what is tested and what is not

Manual Scripted Testing
- Execution:
    - Perform testing as a group, one does tests, others keeps track of tests
    - Follow test suite outlined by Appendix C, execute each test at least once. Verifying actual results match expected results for each case.
    - Mark defects as MFT in the summary field to differentiate them from defects found during exploratory. This creates a list of newly added defect reports.
- Review:
    - After completing manual testing, the defect reports should now be reviewed.
    - The one who performed the previous test should be a participant in reviewing the defect reports
- Benefits:
    - Test cases are easy to follow and reproduce
    - Predetermined steps and expected outcomes make it easier to manage and predict the system
    - Tracking what tests have been and have not been performed is easier
- Tradeoffs:
    - Some scenarios and bugs may be missed if the test suite does not cover enough
    - Time consuming
    - The same bugs are missed all the time

# Notes and discussion of the peer reviews of defect reports

Most of the bugs found affected both Account 1 and 2 equally; There were no account specific bugs found. For example, the bug where withdrawing money from account 1 and account 2 displays three options: Savings, Chequing, and Money Market. Ideally, Account 1 should only display Chequing and Savings, while Account 2 should show Chequing and Money Market. 
<br/>
The notes of our bug reporting can be found in the ./Testing/ folder.

# How the pair testing was managed and team work/effort was divided 

The group split into teams of 2 where Angelo and Nathan found and recorded bugs while using card 1 and Dominic and Karam found and recorded bugs while using card 2. Angelo and Karam had the ATM simulation open on their systems and were responsible for following the exploratory test plan and finding bugs. Nathan and Dominic recorded the bugs that were found and the steps needed to reproduce them. 

# Lessons learned from teamwork on this lab

This lab shows the importance of collaboration between testers. There are a lot of tests that need to be performed and splitting the work is needed for efficiency. Teamwork is also important as other testers may offer a different perspective and see tests differently that could help detect bugs that may not have been evident for another tester. We also learned that managing and coordination within the team is crucial otherwise it will be hard to keep track of the work as more tests are performed. That is why setting up a plan on how to perform tests with other testers would help avoid those issues. 

# Difficulties encountered, challenges overcome, and lessons learned

We had difficulty trying to figure out and use the bug tracking systems. We started with Azure DevOps, but had lots of trouble trying to figure out what was wrong with it.
We ended up switching to Atlassian Jira. We still had some trouble initially with Jira, but it was easier to figure out and we continued with it. 
<br/>
We realized that exploratory and manual testing can sometimes make it easier to spot bugs, but it is also very slow and tedious. We also learned that it is important to perform some tests multiple times as we found that bugs may reveal more depth that otherwise would not have been evident on the first test. Overall, we now have a deeper understanding of different manual testing methods which can be applied to future projects. This lab is a good intro to software testing which will lead us into more efficient modes of testing. 

# Comments/feedback on the lab and lab document itself

The lab document is very long. It could benefit from shorter paragraphs with better explanation, more use of bullet points and lists, and more conciseness in general. We also believe that some links to troubleshooting for common issues with Jira or Azure DevOps would be beneficial to students. This lab also promotes working as a team and shows how important it is to do so when tracking bugs as there a lot of potential defects and some may be left undetected unless a different perspective is offered. Otherwise it was a very informative lab that broadened our understanding of testing software, primarily on how to detect issues and defects and how to handle them.
